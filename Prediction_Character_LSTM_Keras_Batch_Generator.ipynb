{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Prediction_Character_LSTM_Keras_Batch_Generator.ipynb","provenance":[],"mount_file_id":"1GrRFXeU8ES92hoY9SZol_Zuitsuxk0SS","authorship_tag":"ABX9TyOGLmAu+FgWk1XxZIbt1h/z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xVtkpfq1J8Op","colab_type":"code","outputId":"8c965de9-e917-4981-fa8b-15580d58a687","executionInfo":{"status":"ok","timestamp":1591276672841,"user_tz":-330,"elapsed":6568,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","print(keras.__version__)\n","import pandas as pd\n","import numpy as np"],"execution_count":1,"outputs":[{"output_type":"stream","text":["2.2.0\n","2.3.0-tf\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KQd97rKrXWkL","colab_type":"code","colab":{}},"source":["## Load the data from http://www.gutenberg.org/files/1342/1342-0.txt\n","## Datafile path : https://raw.githubusercontent.com/atulpatelDS/Data_Files/master/Book/Pride_and_Prejudice.txt\n","dataset = open(\"Pride_and_Prejudice.txt\",encoding=\"utf8\").read()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hYZ_Tj0weu4N","colab_type":"code","outputId":"896e45fc-b1bb-45d0-b5c7-528d87c065e6","executionInfo":{"status":"ok","timestamp":1591276672846,"user_tz":-330,"elapsed":6557,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["len(dataset),type(dataset)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(775741, str)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"nG-AAdiZeu62","colab_type":"code","outputId":"e7ad7a69-ee80-4647-a702-ae5c49369147","executionInfo":{"status":"ok","timestamp":1591276672847,"user_tz":-330,"elapsed":6549,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["dataset[10000:10020]"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'eas,” he continued, '"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"9n13eSAreu8_","colab_type":"code","colab":{}},"source":["## Tokenize the data as character lavel\n","text = keras.preprocessing.text.Tokenizer(char_level=True,lower=False)\n","text.fit_on_texts(dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-yD4mb_Neu_m","colab_type":"code","outputId":"7c85e3ee-f20d-4e9e-fe43-3d74aed56095","executionInfo":{"status":"ok","timestamp":1591276672849,"user_tz":-330,"elapsed":6540,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["## Vocab size\n","vocab_size = len(text.word_index)  ## Total number of unique char\n","vocab_size"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["92"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Yykow-O-i56D","colab_type":"code","outputId":"42db73e9-bdaa-4fa0-800e-cb18e7580743","executionInfo":{"status":"ok","timestamp":1591276672849,"user_tz":-330,"elapsed":6531,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":56}},"source":["print(text.word_index)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["{' ': 1, 'e': 2, 't': 3, 'a': 4, 'o': 5, 'n': 6, 'i': 7, 'h': 8, 'r': 9, 's': 10, 'd': 11, 'l': 12, 'u': 13, '\\n': 14, 'm': 15, 'c': 16, 'y': 17, 'f': 18, 'w': 19, 'g': 20, ',': 21, 'p': 22, 'b': 23, '.': 24, 'v': 25, 'k': 26, 'I': 27, '“': 28, '”': 29, 'M': 30, ';': 31, 'B': 32, 'z': 33, '_': 34, 'T': 35, 'x': 36, 'E': 37, 'L': 38, 'C': 39, '’': 40, 'H': 41, 'W': 42, 'j': 43, 'q': 44, 'D': 45, 'S': 46, 'A': 47, '!': 48, '?': 49, '-': 50, '—': 51, 'Y': 52, 'J': 53, 'N': 54, 'P': 55, 'G': 56, 'O': 57, 'F': 58, 'R': 59, ':': 60, 'K': 61, '1': 62, 'U': 63, '2': 64, '3': 65, '4': 66, '5': 67, '(': 68, ')': 69, '0': 70, 'V': 71, '*': 72, '6': 73, '/': 74, '8': 75, '9': 76, '7': 77, '‘': 78, 'ê': 79, 'à': 80, 'Z': 81, '[': 82, '#': 83, ']': 84, 'X': 85, \"'\": 86, '@': 87, '$': 88, '\\ufeff': 89, 'é': 90, '%': 91, 'Q': 92}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I-v-4_Qyi58W","colab_type":"code","colab":{}},"source":["## Convert text(characters ) to number\n","text_to_num = text.texts_to_sequences(dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcuJBp1sk6Jj","colab_type":"code","outputId":"bbf43b29-148d-4610-d2c4-c5dce9687fc2","executionInfo":{"status":"ok","timestamp":1591276673772,"user_tz":-330,"elapsed":7442,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["type(text_to_num),len(text_to_num)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(list, 775741)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"EQfvqRwZlok0","colab_type":"code","outputId":"b6634b61-a07f-476a-e406-d8e6c08a2237","executionInfo":{"status":"ok","timestamp":1591276673774,"user_tz":-330,"elapsed":7438,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["print(dataset[10000:10020])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["eas,” he continued, \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KPKHl20kk6MW","colab_type":"code","outputId":"2d8182af-208a-4c25-ee5c-b57c53c4b82b","executionInfo":{"status":"ok","timestamp":1591276673775,"user_tz":-330,"elapsed":7434,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":56}},"source":["## Print the char numbers ,verify with print(text.word_index)\n","print(text_to_num[10000:10020])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[[2], [4], [10], [21], [29], [1], [8], [2], [1], [16], [5], [6], [3], [7], [6], [13], [2], [11], [21], [1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1fa-VJOUi5-H","colab_type":"code","colab":{}},"source":["## We would also need dictionary which can convert these numbers to character\n","num_to_text = dict((n,c) for c,n in text.word_index.items())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cXVD8TYlxNL","colab_type":"code","outputId":"89fabc7a-43be-4d1e-fb20-f21dd3ff107f","executionInfo":{"status":"ok","timestamp":1591276674376,"user_tz":-330,"elapsed":8023,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":56}},"source":["print(num_to_text)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["{1: ' ', 2: 'e', 3: 't', 4: 'a', 5: 'o', 6: 'n', 7: 'i', 8: 'h', 9: 'r', 10: 's', 11: 'd', 12: 'l', 13: 'u', 14: '\\n', 15: 'm', 16: 'c', 17: 'y', 18: 'f', 19: 'w', 20: 'g', 21: ',', 22: 'p', 23: 'b', 24: '.', 25: 'v', 26: 'k', 27: 'I', 28: '“', 29: '”', 30: 'M', 31: ';', 32: 'B', 33: 'z', 34: '_', 35: 'T', 36: 'x', 37: 'E', 38: 'L', 39: 'C', 40: '’', 41: 'H', 42: 'W', 43: 'j', 44: 'q', 45: 'D', 46: 'S', 47: 'A', 48: '!', 49: '?', 50: '-', 51: '—', 52: 'Y', 53: 'J', 54: 'N', 55: 'P', 56: 'G', 57: 'O', 58: 'F', 59: 'R', 60: ':', 61: 'K', 62: '1', 63: 'U', 64: '2', 65: '3', 66: '4', 67: '5', 68: '(', 69: ')', 70: '0', 71: 'V', 72: '*', 73: '6', 74: '/', 75: '8', 76: '9', 77: '7', 78: '‘', 79: 'ê', 80: 'à', 81: 'Z', 82: '[', 83: '#', 84: ']', 85: 'X', 86: \"'\", 87: '@', 88: '$', 89: '\\ufeff', 90: 'é', 91: '%', 92: 'Q'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Rf1C-QSqnIWb","colab_type":"text"},"source":["Lets Prepare input and output sequences\n","\n","1. input data will have sequence with 30 characters\n","Note: If we take large size then we must have enough memory eg.100GB more to work properly so we taking less sequence data\n","2. output data will have one character which come after 30 characters in the input data"]},{"cell_type":"code","metadata":{"id":"J3bq__LQlxQF","colab_type":"code","colab":{}},"source":["## Characters sequence length\n","sequence_length = 30\n","input_data = []\n","output_data = []\n","\n","## feed data in both empty lists\n","for i in range(0,len(text_to_num)-sequence_length):\n","  input_seq = text_to_num[i:i+sequence_length]\n","  output_seq = text_to_num[i+sequence_length]\n","  input_data.append(input_seq)\n","  output_data.append(output_seq)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3oa3ii83qd-D","colab_type":"code","outputId":"6c8f00ac-8326-4493-c7f0-436bbaf005e0","executionInfo":{"status":"ok","timestamp":1591276675759,"user_tz":-330,"elapsed":9396,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"source":["print(type(input_data))\n","print(type(output_data))\n","print(len(input_data[0]))\n","print(len(output_data[0]))\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","<class 'list'>\n","30\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CbxYEuUaqeAS","colab_type":"code","outputId":"7c008f18-788c-4f39-9e0a-2b887a021aaa","executionInfo":{"status":"ok","timestamp":1591276675760,"user_tz":-330,"elapsed":9392,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}},"colab":{"base_uri":"https://localhost:8080/","height":74}},"source":["print(input_data[0:1])\n","print(output_data[0:1])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[[[89], [14], [35], [8], [2], [1], [55], [9], [5], [43], [2], [16], [3], [1], [56], [13], [3], [2], [6], [23], [2], [9], [20], [1], [37], [32], [5], [5], [26], [1]]]\n","[[5]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oDOPKg52qeC2","colab_type":"code","colab":{}},"source":["## Now we will do one hot encoding for input and output data\n","input_data_one_hot = keras.utils.to_categorical(input_data,num_classes=vocab_size+1) \n","## we added 1 becuase one hot start from 0 so it measn 0 to 92\n","output_data_one_hot = keras.utils.to_categorical(output_data,num_classes=vocab_size+1) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_llmQPnPIs3E","colab_type":"text"},"source":["Input Memory Size \n","1. If we take input sequence array =100 numbers\n","2. Total no of sequences = 775741-100=775641 numbers\n","3. 1 character will have total number due to one hot encoding = 92 numbers\n","4. I integer = 4 bytes\n","5. Total memory(RAM) required for input sequences\n","= 100 * 775641 == 77564100 * 92 === 4 * 71358972\n"," = 28GB\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RT9mF0EWPlqO","colab_type":"text"},"source":["We don't need to feed all data input sequences at onces. We can feed data in batches and keep memory size less.\n","Lets take \n","1. Batch Size = 64\n","2. size of sequence = 100\n","3. Size of each char = 92 (due to one hot)\n","4. number of bytes per integer = 4\n","5. memory required per batch = 64 * 100 * 92 * 4\n","6 . 2.35MB\n","7. If we feed all data with sequence of 100 then memory required 28GB"]},{"cell_type":"code","metadata":{"id":"dcXYSQmkIsIk","colab_type":"code","colab":{}},"source":["## Lets create batch Generator\n","start_batch_num = 0 #starting batch number\n","sequence_length = 100 ## input datas equence length\n","def batch_generator(batch_size = 64):\n","  global start_batch_num  ## need to update batch number\n","\n","  while True:\n","    input_data = []\n","    output_data = []\n","    for i in range(batch_size):\n","      input_seq = text_to_num[(start_batch_num*sequence_length):(start_batch_num*sequence_length)+sequence_length]\n","      output_seq = text_to_num[start_batch_num*sequence_length+sequence_length]\n","\n","      ## add input_seq and output_seq in empty list\n","      input_data.append(input_seq)\n","      output_data.append(output_seq)\n","\n","      start_batch_num = start_batch_num+1\n","\n","      if((start_batch_num*sequence_length+sequence_length)>len(text_to_num)):\n","        start_batch_num=0\n","\n","    ## Input_data and output_data one hot encoding\n","    input_data = keras.utils.to_categorical(input_data,num_classes=vocab_size+1)\n","    output_data = keras.utils.to_categorical(output_data,num_classes=vocab_size+1)\n","\n","    ## Reshape input data in 3d numpy array\n","    # batch_size,sequence_length,vocab_size+1\n","    input_data = np.reshape(input_data,(len(input_data),sequence_length,vocab_size+1))\n","\n","    yield input_data,output_data  ## yield becuase we want data again and again\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMnadt2XtZm1","colab_type":"code","colab":{}},"source":["## Bulid the graph\n","sequence_length_batch = 100\n","model = keras.models.Sequential()\n","model.add(keras.layers.LSTM(256,input_shape=(sequence_length_batch,vocab_size+1)))\n","model.add(keras.layers.Dropout(0.2))\n","model.add(keras.layers.Dense(units=vocab_size+1,activation=\"softmax\")) ## No of predictions : vocab_size+1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"On1sUD9VtZtl","colab_type":"code","colab":{}},"source":["model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\")  ## not required accuracy only loss is sufficient"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6r5WH9dqyRKP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"9772d961-3929-4f28-99cb-4ba93cba8a58","executionInfo":{"status":"ok","timestamp":1591276688999,"user_tz":-330,"elapsed":22609,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}}},"source":["## Lets take randomply selecting the sequence from dataset and we will print the output and see how model is learning\n","\n","start_seq = np.random.randint(0,high=(len(text_to_num)-sequence_length_batch))\n","start_seq"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["401174"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"ZfBXd1CWyRM_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":74},"outputId":"4477e7ca-9ead-4b77-9f86-98cded665d65","executionInfo":{"status":"ok","timestamp":1591276688999,"user_tz":-330,"elapsed":22602,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}}},"source":["test_seq= text_to_num[start_seq:start_seq+sequence_length_batch]\n","print(test_seq)\n","print(len(test_seq))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["[[2], [12], [12], [1], [4], [10], [10], [13], [9], [2], [11], [1], [5], [18], [1], [8], [7], [10], [14], [1], [1], [1], [1], [1], [1], [16], [5], [13], [10], [7], [6], [40], [10], [1], [16], [5], [9], [9], [5], [23], [5], [9], [4], [3], [7], [5], [6], [24], [14], [14], [1], [1], [1], [1], [1], [1], [46], [8], [2], [1], [22], [2], [9], [18], [2], [16], [3], [12], [17], [1], [9], [2], [15], [2], [15], [23], [2], [9], [2], [11], [1], [2], [25], [2], [9], [17], [3], [8], [7], [6], [20], [1], [3], [8], [4], [3], [1], [8], [4], [11]]\n","100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VyoGEnku2XjD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"9062f796-3221-46ff-e73c-9ffe2e47fbd5","executionInfo":{"status":"ok","timestamp":1591276689000,"user_tz":-330,"elapsed":22597,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}}},"source":["test_seq[2][0]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"LCm15yYiyRPN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"outputId":"aa784cab-559d-4a9d-ba5b-cd67fa8faa94","executionInfo":{"status":"ok","timestamp":1591276689002,"user_tz":-330,"elapsed":22594,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}}},"source":["## Lets print the random 100characters sequence for prediction\n","print(\"Input sequence is :\")\n","for i in range(sequence_length_batch):\n","  print(num_to_text[test_seq[i][0]],end=\"\")\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Input sequence is :\n","ell assured of his\n","      cousin’s corroboration.\n","\n","      She perfectly remembered everything that had"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tpPKZ8fNyRRL","colab_type":"code","colab":{}},"source":["## Lets create a Prediction function which will be called white model perform training.\n","def predict_seq_while_training(epoch,logs):\n","  print(\"\\n\\nOutput sequence after each epoch \", epoch, \" :\")\n","  predicted_output = \"\"  ## initilize null predicted and alter we will update this\n","  current_seq = np.copy(test_seq)  ## just only for taking new copy of test_sequence\n","  for i in range(50): ## lets predict 50 output characters\n","    current_seq_one_hot = keras.utils.to_categorical(current_seq,num_classes=vocab_size+1)\n","    input_data_feed = np.reshape(current_seq_one_hot,\n","                                 (1,current_seq_one_hot.shape[0],current_seq_one_hot.shape[1]))\n","    ## Now predict the character max probability\n","    predicted_char_num = np.argmax(model.predict(input_data_feed)[0])\n","    ## we are going to predict 50 characters so we need to concat each 50 output\n","    ## Also need to convert num to char\n","    if (predicted_char_num != 0):\n","      predicted_output = predicted_output + num_to_text[predicted_char_num]\n","    ## now need to feed new input sequence so we have to update it\n","    ## Update input sequence with new value at the end\n","    current_seq = np.roll(current_seq,-1)\n","    current_seq[current_seq.shape[0]-1] = [predicted_char_num]\n","  print(predicted_output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QJrEqy7hEARl","colab_type":"code","colab":{}},"source":["## Lets execute the Model\n","## use lambdacallback to do the prediction at the end of each epoch\n","lambda_checkpoint = keras.callbacks.LambdaCallback(on_epoch_begin=predict_seq_while_training)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-vy7GUpEAZ7","colab_type":"code","colab":{}},"source":["## Create Model Checkpoint to store model after each epoch if loss reduce\n","checkpoint_filepath = 'sample_data/char_rnn.h5'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    #save_weights_only=True,\n","    monitor='loss',\n","    #mode='max',\n","    save_best_only=True,\n","    verbose=1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YkUghA_2EAc0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c975f550-e46c-4b32-851d-2056acf3b484","executionInfo":{"status":"ok","timestamp":1591278075927,"user_tz":-330,"elapsed":1252038,"user":{"displayName":"Atul Patel","photoUrl":"","userId":"07050373690176037615"}}},"source":["batch_size = 64\n","train_batch_generator = batch_generator(batch_size=batch_size)\n","model.fit_generator(train_batch_generator,\n","                    epochs=10,\n","                    steps_per_epoch=(len(text_to_num)-sequence_length_batch)//batch_size,\n","                    callbacks=[model_checkpoint_callback,lambda_checkpoint])\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-28-249414b4292f>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","\n","\n","Output sequence after each epoch  0  :\n",")@@9“DtDWvYYYpppppAAdd)àhf!]Jd)àhf!]J40K$4vvYYYYpp\n","Epoch 1/10\n","12115/12119 [============================>.] - ETA: 0s - loss: 0.8009\n","Epoch 00001: loss improved from inf to 0.80062, saving model to sample_data/char_rnn.h5\n","12119/12119 [==============================] - 138s 11ms/step - loss: 0.8006\n","\n","\n","Output sequence after each epoch  1  :\n"," beener he wally o  h  ever ma\n","\n","      seed, and th\n","Epoch 2/10\n","12119/12119 [==============================] - ETA: 0s - loss: 0.0380\n","Epoch 00002: loss improved from 0.80062 to 0.03802, saving model to sample_data/char_rnn.h5\n","12119/12119 [==============================] - 137s 11ms/step - loss: 0.0380\n","\n","\n","Output sequence after each epoch  2  :\n"," been, whin her mond; bntreeuththouth she was dong\n","Epoch 3/10\n","12118/12119 [============================>.] - ETA: 0s - loss: 0.0221\n","Epoch 00003: loss improved from 0.03802 to 0.02207, saving model to sample_data/char_rnn.h5\n","12119/12119 [==============================] - 137s 11ms/step - loss: 0.0221\n","\n","\n","Output sequence after each epoch  3  :\n"," been, whin her more she predided\n","      he houthor\n","Epoch 4/10\n","12119/12119 [==============================] - ETA: 0s - loss: 0.0186\n","Epoch 00004: loss improved from 0.02207 to 0.01860, saving model to sample_data/char_rnn.h5\n","12119/12119 [==============================] - 137s 11ms/step - loss: 0.0186\n","\n","\n","Output sequence after each epoch  4  :\n"," been she dabeed, when her mome\n","      cancare and \n","Epoch 5/10\n","12117/12119 [============================>.] - ETA: 0s - loss: 0.0130\n","Epoch 00005: loss improved from 0.01860 to 0.01301, saving model to sample_data/char_rnn.h5\n","12119/12119 [==============================] - 137s 11ms/step - loss: 0.0130\n","\n","\n","Output sequence after each epoch  5  :\n"," been she daser the ever, and the\n","      fer morlis\n","Epoch 6/10\n","12115/12119 [============================>.] - ETA: 0s - loss: 0.0119\n","Epoch 00006: loss improved from 0.01301 to 0.01194, saving model to sample_data/char_rnn.h5\n","12119/12119 [==============================] - 137s 11ms/step - loss: 0.0119\n","\n","\n","Output sequence after each epoch  6  :\n"," sien the fured of dingen\n","      got thound of that\n","Epoch 7/10\n","12115/12119 [============================>.] - ETA: 0s - loss: 0.0094\n","Epoch 00007: loss improved from 0.01194 to 0.00945, saving model to sample_data/char_rnn.h5\n","12119/12119 [==============================] - 137s 11ms/step - loss: 0.0095\n","\n","\n","Output sequence after each epoch  7  :\n"," been, whith you mott I fereed\n","      thatk moon th\n","Epoch 8/10\n","12119/12119 [==============================] - ETA: 0s - loss: 0.0091\n","Epoch 00008: loss improved from 0.00945 to 0.00907, saving model to sample_data/char_rnn.h5\n","12119/12119 [==============================] - 137s 11ms/step - loss: 0.0091\n","\n","\n","Output sequence after each epoch  8  :\n"," been sented inlliven, what hh m mennisien\n","      m\n","Epoch 9/10\n","12116/12119 [============================>.] - ETA: 0s - loss: 0.0070\n","Epoch 00009: loss improved from 0.00907 to 0.00695, saving model to sample_data/char_rnn.h5\n","12119/12119 [==============================] - 137s 11ms/step - loss: 0.0070\n","\n","\n","Output sequence after each epoch  9  :\n"," beingey that whel femied\n","\n","      “Buthith you goo \n","Epoch 10/10\n","12116/12119 [============================>.] - ETA: 0s - loss: 0.0068\n","Epoch 00010: loss improved from 0.00695 to 0.00683, saving model to sample_data/char_rnn.h5\n","12119/12119 [==============================] - 137s 11ms/step - loss: 0.0068\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f9f6e0b4278>"]},"metadata":{"tags":[]},"execution_count":28}]}]}