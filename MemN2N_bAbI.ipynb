{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MemN2N_bAbI_Task_1.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kFVu78ger5i4","colab_type":"text"},"source":["## MemN2N Network- Facebook Babi Task Dataset\n","\n","https://research.fb.com/downloads/babi/\n","\n","https://github.com/facebookarchive/bAbI-tasks\n","\n","We can read this paper to get more details about MemN2N network\n","\n","https://arxiv.org/abs/1503.08895"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"28LkzM4kKvNw","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HSJ-WEVjKvNz"},"source":["#### Download the data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6ybzStAUKvN1","colab":{}},"source":["#Uncomment to download the file\n","#!wget https://github.com/atulpatelDS/Data_Files/tree/master/Facebook_datasets/tasks_1-20_v1-2.tar.gz --quiet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0Hx7Plgr5jM","colab_type":"code","colab":{}},"source":["import requests\n","\n","url = \"https://raw.githubusercontent.com/atulpatelDS/Data_Files/master/Facebook_datasets/tasks_1-20_v1-2.tar.gz\"\n","target_path = 'tasks_1-20_v1-2.tar.gz'\n","response = requests.get(url, stream=True)\n","if response.status_code == 200:\n","    with open(target_path, 'wb') as f:\n","        f.write(response.raw.read())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"beZqb8Zqr5jR","colab_type":"code","colab":{}},"source":["import tarfile\n","\n","with tarfile.open('tasks_1-20_v1-2.tar.gz') as tar:\n","    f = tar.extractfile('tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_test.txt')\n","    print(f.readlines(600))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zT6IaX57KvN6"},"source":["#### Parse bAbI stories"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0rpGiJGxKvN7","colab":{}},"source":["def parse_stories(lines):\n","    \n","    stories = []\n","    questions = []\n","    answers = []\n","    \n","    story = ''\n","    for line in lines:\n","        line = line.decode('utf-8').strip()\n","        #Get line number and rest of the line\n","        nid, line = line.split(' ', 1)\n","        nid = int(nid)\n","        if nid == 1:\n","            #Start a new story\n","            story = ''\n","        if '\\t' in line:\n","            #End of the story\n","            q, a, supporting = line.split('\\t')\n","            stories.append(story)\n","            questions.append(q)\n","            answers.append(a)            \n","        else:\n","            if (story == ''):\n","                story = line\n","            else:\n","                story += ' ' + line\n","    return stories, questions, answers"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JksNOfyJKvN-"},"source":["#### Extract the train and test files"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QEw0BVE2KvOM","colab":{}},"source":["with tarfile.open('tasks_1-20_v1-2.tar.gz') as tar:\n","    \n","    train_file = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_train.txt'\n","    test_file = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_test.txt'\n","    \n","    train_stories_txt, train_q_txt, train_a_txt  = parse_stories(tar.extractfile(train_file))\n","    test_stories_txt, test_q_txt, test_a_txt = parse_stories(tar.extractfile(test_file))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JlK0RI7nr5jm"},"source":["#### Explore dataset"]},{"cell_type":"code","metadata":{"id":"ouKxFEd1r5jo","colab_type":"code","colab":{}},"source":["print('Number of stories in training data: ', len(train_stories_txt))\n","print('Number of stories in test data: ', len(test_stories_txt))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"auIhDLWfKvOU","colab":{}},"source":["#Lets explore examples\n","example_num = 9900\n","\n","print('Story: ', train_stories_txt[example_num])\n","print('Question: ', train_q_txt[example_num])\n","print('Answer: ', train_a_txt[example_num])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"me6Uh_TaKvOb"},"source":["#### Build Tokenizer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yhDpwwTPKvOg","colab":{}},"source":["t = tf.keras.preprocessing.text.Tokenizer()\n","\n","#Fit on training data\n","t.fit_on_texts(train_stories_txt)\n","t.fit_on_texts(train_q_txt)\n","t.fit_on_texts(train_a_txt)\n","\n","#Fit on test data\n","t.fit_on_texts(test_stories_txt)\n","t.fit_on_texts(test_q_txt)\n","t.fit_on_texts(test_a_txt)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yFKCEmutKvO0","colab":{}},"source":["vocab_size =  len(t.word_index) + 1 #Tokenizer starts with index 1\n","print(vocab_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_gQcJzW4KvO3","colab":{}},"source":["#### Convert text to numbers using Tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"D7pO9tErKvO_","colab":{}},"source":["#Training data\n","train_stories_seq = t.texts_to_sequences(train_stories_txt)\n","train_q_seq = t.texts_to_sequences(train_q_txt)\n","train_a_seq = t.texts_to_sequences(train_a_txt)\n","\n","#Test data\n","test_stories_seq = t.texts_to_sequences(test_stories_txt)\n","test_q_seq = t.texts_to_sequences(test_q_txt)\n","test_a_seq = t.texts_to_sequences(test_a_txt)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CUjifp6lKvPC","colab":{}},"source":["#Max Length of Story, Question and Answe\n","story_maxlen = max([len(txt) for txt in train_stories_seq + test_stories_seq])\n","question_maxlen = max([len(txt) for txt in train_q_seq + test_q_seq])\n","answer_maxlen = max([len(txt) for txt in train_a_seq + test_a_seq])\n","\n","print('Max length for ...\\nStory: ', story_maxlen, '\\nQuestion: ',question_maxlen,'\\nAnswer: ',answer_maxlen)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"t8MOmIaIKvPh"},"source":["#### Pad the sequences"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fBfPDOm6KvPj","colab":{}},"source":["pad_sequences = tf.keras.preprocessing.sequence.pad_sequences\n","\n","#Training Data\n","train_stories_seq = pad_sequences(train_stories_seq,maxlen=story_maxlen)\n","train_q_seq = pad_sequences(train_q_seq,maxlen=question_maxlen)\n","train_a_seq = pad_sequences(train_a_seq,maxlen=answer_maxlen)\n","## Even we can ignore padding for answer because answer is always 1 word\n","\n","#Test Data\n","test_stories_seq = pad_sequences(test_stories_seq,maxlen=story_maxlen)\n","test_q_seq = pad_sequences(test_q_seq,maxlen=question_maxlen)\n","test_a_seq = pad_sequences(test_a_seq,maxlen=answer_maxlen)\n","## Even we can ignore padding for answer because answer is always 1 word"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qj1ON1HhKvPo"},"source":["#### Integer to word converter"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f25qq4WgKvPo","colab":{}},"source":["#Required during prediction\n","int_to_word = dict((i,w) for w, i in t.word_index.items())\n","int_to_word[11]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g_g96GYdKvPz"},"source":["### Define the model layers"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BAA07EehKvP3"},"source":["#### Input layers"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UlvMUk3RKvP4","colab":{}},"source":["#Define input for story and question\n","story = tf.keras.layers.Input(shape=(story_maxlen,))\n","question = tf.keras.layers.Input(shape=(question_maxlen,))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LFjKW9_9KvP8"},"source":["### Build 3 encoders to provide 3 Embeddings\n","\n","<ol><li>Input Memory (Story)</li>\n","<li>Output Memory (Story)</li>\n","<li>Question embedding</li></ol>"]},{"cell_type":"markdown","metadata":{"id":"vzkMQDEKr5kh","colab_type":"text"},"source":["<img src=\"https://raw.githubusercontent.com/atulpatelDS/Machine_Learning/master/Images/MemN2N1.PNG\" width=\"540\" height=\"240\" align=\"left\"/>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AT6lHcwWKvP8"},"source":["#### Embedding A for Input memory"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TT0NrPkPKvP9","colab":{}},"source":["a_encoder = tf.keras.models.Sequential()\n","a_encoder.add(tf.keras.layers.Embedding(input_dim=vocab_size,\n","                                        output_dim=story_maxlen))\n","a_encoder.add(tf.keras.layers.Dropout(0.3))\n","a_embedded_output = a_encoder(story)\n","#output is batch_size x story_maxlen x story_maxlen (embedding size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"htxep4nyr5kl","colab_type":"code","colab":{}},"source":["a_encoder,a_embedded_output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4lg0FbE9KvQB"},"source":["#### Embedding B for Question"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ihO-mSyzKvQE","colab":{}},"source":["b_question_encoder = tf.keras.models.Sequential()\n","b_question_encoder.add(tf.keras.layers.Embedding(input_dim=vocab_size, \n","                                               output_dim=story_maxlen, \n","                                               input_length=question_maxlen))\n","b_question_encoder.add(tf.keras.layers.Dropout(0.3))\n","b_question_embeddding_output = b_question_encoder(question)\n","#output is batch_size x question_maxlen x story_maxlen (embedding size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9AFiBc1r5kt","colab_type":"code","colab":{}},"source":["b_question_embeddding_output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"f6rcesQlKvP-"},"source":["#### Embedding C for Story, to use with Controller"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5das9VdBKvP_","colab":{}},"source":["c_encoder = tf.keras.models.Sequential()\n","c_encoder.add(tf.keras.layers.Embedding(input_dim=vocab_size, \n","                                        output_dim=question_maxlen))\n","c_encoder.add(tf.keras.layers.Dropout(0.3))\n","c_embedded_output = c_encoder(story)\n","#output is batch_size x story_maxlen x question_maxlen (embedding size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"On-c9Wq4r5k2","colab_type":"code","colab":{}},"source":["c_embedded_output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Rhqinx5nKvQJ"},"source":["### Attention layer"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gdChjUUHr5k5"},"source":["#### Alignment Weights"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T4xjYgaKKvQK","colab":{}},"source":["attention_weights = tf.keras.layers.dot([a_embedded_output, b_question_embeddding_output], \n","                                        axes=(2, 2))\n","attention_weights = tf.keras.layers.Activation('softmax')(attention_weights)\n","#output is batch_size x story_maxlen x question_maxlen"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFGCTDHcr5k-","colab_type":"code","colab":{}},"source":["attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N94GOAi7KvQM"},"source":["#### Calculate Context Vector / Weighted sum (here we are using Add function)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cb6uVM6eKvQM","colab":{}},"source":["weighted_sum = tf.keras.layers.add([attention_weights, c_embedded_output])  \n","#Output batch_size x story_maxlen x question_maxlen\n","\n","permuted_weighted_sum = tf.keras.layers.Permute((2, 1))(weighted_sum)  \n","#Output batch_size x question_maxlen x story_maxlen"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wWpFSVoir5lD","colab_type":"code","colab":{}},"source":["weighted_sum ,permuted_weighted_sum "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5zDBtEQrr5lG","colab_type":"text"},"source":["<img src=\"https://raw.githubusercontent.com/atulpatelDS/Machine_Learning/master/Images/MemN2N.PNG\" width=\"540\" height=\"240\" align=\"left\"/>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OBEIWRbcKvQS"},"source":["##### Add both Context vector to Question embedding (for first hop)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WQiaMcrhKvQS","colab":{}},"source":["output_1 = tf.keras.layers.add([permuted_weighted_sum, b_question_embeddding_output])\n","#Output batch_size x query_maxlen x story_maxlen\n","output_1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XmQTVPslKvQV"},"source":["#### Output using LSTM"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"s9QfrkC-KvQV","colab":{}},"source":["final_output = tf.keras.layers.LSTM(32)(output_1)\n","#Last hidden state - batch_size x 32\n","\n","#Add dropout\n","final_output = tf.keras.layers.Dropout(0.3)(final_output)\n","\n","#Output layer\n","answer = tf.keras.layers.Dense(vocab_size + 1 , activation='softmax')(final_output)\n","#Output batch_size x vocab_size"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3bsnM7GlKvQu"},"source":["### Build the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Sg36B3AEKvQw","colab":{}},"source":["model = tf.keras.models.Model([story, question], answer)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nnOPS6coKvQ3"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ej5DWSWAKvQ4","colab":{}},"source":["model.fit([train_stories_seq, train_q_seq], train_a_seq,\n","          batch_size=32,\n","          epochs=500,\n","          validation_data=([test_stories_seq, test_q_seq], test_a_seq))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zhqYAJaJKvQ9","colab":{}},"source":["model.save('models\\babi_memn2n.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xd262rYfr5lZ","colab_type":"code","colab":{}},"source":["model = tf.keras.models.load_model('models\\babi_memn2n.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XHQs_ohjKvRA"},"source":["### Model Prediction"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qvhUqqhTr5lb"},"source":["#### Prediction function"]},{"cell_type":"code","metadata":{"id":"Ma_-WxMwr5lb","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def predict_answer(test_num):\n","\n","    #Get padded story seuqence\n","    story_seq_ex = test_stories_seq[test_num]\n","\n","    #Get padded question sequence\n","    question_seq_ex = test_q_seq[test_num]\n","\n","    #reshape to batch_size 1\n","    story_seq_ex = np.reshape(story_seq_ex,(1,len(story_seq_ex)))\n","    question_seq_ex = np.reshape(question_seq_ex,(1,len(question_seq_ex)))\n","\n","    #Predict\n","    result = model.predict([story_seq_ex, question_seq_ex])\n","\n","    #Get the index with highest probability\n","    result = np.argmax(result)\n","\n","    #Convert index to word\n","    result = int_to_word[result]\n","    \n","    return result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g60qRZxHKvRF","colab":{}},"source":["#### Test Predictions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cOBWi7lxr5lg","colab_type":"code","colab":{}},"source":["test_num = 789\n","#test_num = np.random.randint(0, len(test_stories_txt))   #random story number e.g. 789, 885 etc\n","print ('Story number: ', test_num)\n","print (test_stories_txt[test_num])\n","print ('\\nQuestion: ' + test_q_txt[test_num])\n","print ('Answer: ' + predict_answer(test_num))"],"execution_count":0,"outputs":[]}]}